# markov-traffic-predictor
> Markov chains in website traffic prediction
Predicts which pages in a network of websites (the internet) a user will land
on after starting on a given page. Inspired by PageRank.

## About
Getting lost in Wikipedia holes is an enjoyable pastimeâ€”but is there a way to
simulate getting lost in the forest of links? Using Markov chains, we can
simulate a user starting at some page A and find the most likely pages that
user ends up after a certain number (n) random link clicks.

## Quickstart
### Setup
First clone this repo, then install the dependencies in **src/requirements.txt** with
```sh
pip install -r requirements.txt
```
Next, update `START_PAGE` in **src/spider.py** to make the web crawler start at
a different page when creating a snapshot of the internet.

Additionally, update the following in **src/spider.py** if you want the crawler
to look at all HTTPS URLs instead of subpages of Wikipedia (in this example).
```py
for link in soup.find_all('a', attrs={'href': re.compile('^/wiki/')}):
    href = 'https://en.wikipedia.org' + link.get('href')
```

Lastly, update the page you'd like to start the Markov chain at by changing the
value of `START_LINK` in **src/page_rank_markov.py**. Note that this page must
be in the **src/link_ids.json** generated by **src/spider.py**.

### Run the Markov Model
In the **src** folder:
1. Run **spider.py**
2. Run **markov_matrix_creator.py**
3. Run **page_rank_markov.py** to get the predictions of the 10 most likely
   websites visited

## References
1. [Wikipedia. PageRank](https://en.wikipedia.org/wiki/PageRank)
1. [Stanford CS54N. PageRank](https://web.stanford.edu/class/cs54n/handouts/24-GooglePageRankAlgorithm.pdf)
1. [MIT 6.S191: Recurrent Neural Networks](https://www.youtube.com/watch?v=qjrad0V0uJE&list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI&index=3)
